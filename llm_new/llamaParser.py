import requests
import json
import re
import time
from typing import Dict, Any, Optional

class NeuralBookParser:
    def __init__(self, base_url: str = "http://localhost:11434"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é Llama 3.1
        
        Args:
            base_url: URL –ª–æ–∫–∞–ª—å–Ω–æ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ Ollama
        """
        self.base_url = base_url
        self.completion_url = f"{base_url}/api/chat"
        self.system_prompt = ""
        self.is_initialized = False
        
    def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–∞
        
        Returns:
            True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞
        """
        print("üîç –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        if not self._test_connection():
            print("‚ùå –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return False
        
        print("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        print("üìñ –ó–∞–≥—Ä—É–∂–∞—é —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç...")
        self.system_prompt = self._load_system_prompt()
        
        if not self.system_prompt:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
            return False
        
        print("‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º...")
        initialization_success = self._initialize_neural_network()
        
        if initialization_success:
            print("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            self.is_initialized = True
            return True
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
            return False
    
    def _test_connection(self) -> bool:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        
        Returns:
            True –µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            return response.status_code == 200
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return False
    
    def _load_system_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞
        
        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        """
        try:
            with open('mainPromtOnStart.md', 'r', encoding='utf-8') as file:
                content = file.read().strip()
                print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–º–ø—Ç –¥–ª–∏–Ω–æ–π {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                return content
        except FileNotFoundError:
            print("‚ö†Ô∏è –§–∞–π–ª mainPromtOnStart.md –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return ""
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")
            return ""
    
    def _initialize_neural_network(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ - —Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã
        """
        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
            test_payload = {
                "model": "llama3.1:8b-instruct-q4_0",
                "messages": [
                    {"role": "user", "content": "–û—Ç–≤–µ—Ç—å 'READY' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã"}
                ],
                "stream": False
            }
            
            response = requests.post(
                self.completion_url,
                json=test_payload,
                headers={"Content-Type": "application/json"},
                timeout=50  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["message"]["content"].strip()
                print(f"ü§ñ –û—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ø—Ä–∏ —Ç–µ—Å—Ç–µ: {content}")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {e}")
            return False

    def parse_query(self, user_query: str) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        if not self.is_initialized:
            print("‚ùå –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –í—ã–∑–æ–≤–∏—Ç–µ initialize() —Å–Ω–∞—á–∞–ª–∞.")
            return self._get_empty_template()
        
        print(f"ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å: '{user_query}'")
        
        try:
            # –í –ö–ê–ñ–î–û–ú –∑–∞–ø—Ä–æ—Å–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç + –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
            payload = {
                "model": "llama3.1:8b-instruct-q4_0",
                "messages": [
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_query}
                ],
                "stream": False
            }
            
            start_time = time.time()
            response = requests.post(
                self.completion_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                timeout=180
            )
            processing_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result["message"]["content"].strip()
                
                print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
                json_data = self._extract_json_from_response(content)
                print(json_data)
                # –í–°–ï–ì–î–ê –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è)
                normalized_data = self._normalize_json_structure(json_data)
                print("‚úÖ JSON –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω")
                return normalized_data
                    
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {response.status_code}")
                return self._get_empty_template()
                
        except requests.exceptions.Timeout:
            print("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
            return self._get_empty_template()
        except requests.exceptions.ConnectionError:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
            return self._get_empty_template()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é: {e}")
            return self._get_empty_template()

    def _normalize_json_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π
        """
        # –ë–µ—Ä–µ–º –ø—É—Å—Ç–æ–π —à–∞–±–ª–æ–Ω
        normalized = self._get_empty_template()
        
        # –ï—Å–ª–∏ data –Ω–µ —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —à–∞–±–ª–æ–Ω
        if not isinstance(data, dict) or not data:
            return normalized
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞
        question_type = None
        for possible_key in ['question_type', 'class', 'type', 'questionType']:
            if possible_key in data and data[possible_key]:
                question_type = data[possible_key]
                break
        
        if question_type:
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            type_mapping = {
                "recommendation": "recommendation",
                "search": "search", 
                "find": "search",
                "compare": "comparison",
                "comparison": "comparison",
                "general_question": "general",
                "general": "general",
                "question": "general",
                "step_back": "step_back",
                "back": "step_back",
                "return": "step_back",
                "other": "other",
                "hello": "other",
                "help": "other",
                "thanks": "other",
                "thank you": "other",
                "bye": "other",
                "exit": "other"
            }
            normalized["question_type"] = type_mapping.get(question_type.lower(), question_type)
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        filter_data = data.get("filter", {})
        if not filter_data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –≤ –∫–æ—Ä–Ω–µ –æ–±—ä–µ–∫—Ç–∞
            filter_fields = ["author", "publisher", "year_from", "year_to", "language", 
                        "age_restriction", "genre", "pages_from", "pages_to", "has_illustrations"]
            root_filter = {}
            for field in filter_fields:
                if field in data:
                    root_filter[field] = data[field]
            if root_filter:
                filter_data = root_filter
        
        if isinstance(filter_data, dict):
            for field in normalized["filter"]:
                if field in filter_data:
                    value = filter_data[field]
                    if value is not None and value != "":
                        # –î–ª—è –ø–æ–ª–µ–π-—Å–ø–∏—Å–∫–æ–≤ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
                        if field in ["author", "publisher", "language", "age_restriction", "genre"]:
                            if isinstance(value, list):
                                normalized["filter"][field] = [str(item) for item in value if item]
                            elif isinstance(value, str) and value:
                                normalized["filter"][field] = [value]
                            elif value:
                                normalized["filter"][field] = [str(value)]
                        else:
                            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                            normalized["filter"][field] = str(value)
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        compare_data = data.get("compare", {})
        if isinstance(compare_data, dict):
            for field in normalized["compare"]:
                if field in compare_data:
                    value = compare_data[field]
                    if value is not None and value != "":
                        normalized["compare"][field] = str(value)
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º feedback - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        feedback_data = data.get("feedback", {})
        if not feedback_data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è feedback
            for possible_key in ['likes', 'dislikes', 'preferences', 'feedback']:
                if possible_key in data:
                    if possible_key == 'likes':
                        feedback_data = {"likes": data['likes']}
                    elif possible_key == 'dislikes':
                        feedback_data = {"dislikes": data['dislikes']}
                    elif isinstance(data[possible_key], dict):
                        feedback_data = data[possible_key]
                    break
        
        if isinstance(feedback_data, dict):
            for field in ["likes", "dislikes"]:
                if field in feedback_data:
                    value = feedback_data[field]
                    if value is not None:
                        if isinstance(value, list):
                            normalized["feedback"][field] = [str(item) for item in value if item]
                        elif isinstance(value, str) and value:
                            normalized["feedback"][field] = [value]
                        elif value:
                            normalized["feedback"][field] = [str(value)]
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
        for field in ["num_question", "step_back"]:
            if field in data:
                value = data[field]
                if value is not None and value != "":
                    normalized[field] = str(value)
        
        # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞ –≤—Å–µ –µ—â–µ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        if not normalized["question_type"]:
            if normalized["feedback"].get("likes") or normalized["feedback"].get("dislikes"):
                normalized["question_type"] = "recommendation"
            elif normalized["compare"].get("count_books") and int(normalized["compare"].get("count_books", 0)) >= 2:
                normalized["question_type"] = "comparison"
            elif any(normalized["filter"].values()):
                normalized["question_type"] = "search"
            elif normalized.get("step_back"):
                normalized["question_type"] = "step_back"
            elif normalized.get("num_question"):
                normalized["question_type"] = "other"
        
        return normalized
    
    def _extract_json_from_response(self, content: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        try:
            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ–±–µ—Ä—Ç–∫–∏ –∫–æ–¥–∞
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –æ–±–µ—Ä—Ç–∫–∏, –∏—â–µ–º JSON-–æ–±—ä–µ–∫—Ç
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    json_str = content
            
            # # –ß–∏—Å—Ç–∏–º —Å—Ç—Ä–æ–∫—É –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            # json_str = json_str.strip()
            
            # # –û–ë–ù–û–í–õ–ï–ù–ò–ï: –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON
            # json_str = self._fix_common_json_errors(json_str)
            
            # –ü–∞—Ä—Å–∏–º JSON
            parsed_data = json.loads(json_str)
            return parsed_data
            
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç–≤–µ—Ç–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {content[:500]}")
            return self._get_empty_template()
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ JSON: {e}")
            return self._get_empty_template()

    def _fix_common_json_errors(self, json_str: str) -> str:
        """
        –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ –≤ JSON –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        """
        # –ó–∞–º–µ–Ω—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –¥–≤–æ–π–Ω—ã–µ
        json_str = re.sub(r"(?<!\\)'", '"', json_str)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –º–∞—Å—Å–∏–≤–æ–≤
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        json_str = re.sub(r':\s*([^"\s][^,}\]]*?)\s*([,}\]])', r': "\1"\2', json_str)
        
        return json_str
    
    def _validate_json_structure(self, data: Dict[str, Any]) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞
        
        Args:
            data: –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
            if not isinstance(data, dict):
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ question_type
            if "question_type" not in data:
                return False
            
            question_type = data["question_type"]
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞
            question_type = self._normalize_question_type(question_type)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —Ç–∏–ø—ã –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π
            if "filter" in data and not isinstance(data["filter"], dict):
                return False
            if "compare" in data and not isinstance(data["compare"], dict):
                return False
            if "feedback" in data and not isinstance(data["feedback"], dict):
                return False
            
            # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
            if question_type == "recommendation":
                # –î–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—Ä–æ–≤–µ—Ä—è–µ–º feedback –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if "feedback" in data:
                    if not isinstance(data["feedback"].get("likes", []), list):
                        return False
                    if not isinstance(data["feedback"].get("dislikes", []), list):
                        return False
            
            elif question_type == "search":
                # –î–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º filter –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if "filter" in data:
                    for field in ["author", "publisher", "language", "age_restriction", "genre"]:
                        if field in data["filter"] and not isinstance(data["filter"][field], list):
                            # –ï—Å–ª–∏ –ø–æ–ª–µ –µ—Å—Ç—å, –Ω–æ –Ω–µ —Å–ø–∏—Å–æ–∫, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å
                            if not isinstance(data["filter"][field], (str, int, float)):
                                return False
            
            elif question_type == "compare":
                # –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—è–µ–º compare
                if "compare" not in data:
                    return False
            
            elif question_type == "general_question":
                # –î–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å–ø–æ—Å–æ–± –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–Ω–∏–≥—É
                has_identifiers = False
                if "filter" in data:
                    for field in ["author", "publisher", "language", "age_restriction", "genre"]:
                        if data["filter"].get(field):
                            has_identifiers = True
                            break
                if not has_identifiers:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ compare –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    if "compare" in data:
                        for i in range(1, 3):
                            if data["compare"].get(f"title{i}"):
                                has_identifiers = True
                                break
                    if not has_identifiers:
                        return False
            
            elif question_type == "step_back":
                # –î–ª—è —à–∞–≥–∞ –Ω–∞–∑–∞–¥ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ step_back
                step_back = data.get("step_back", "")
                if step_back not in ["1", "-1"]:
                    return False
            
            elif question_type == "other":
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å num_question
                num_question = data.get("num_question", "")
                if not num_question:
                    return False
            
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞
                return False
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            return False

    def _normalize_question_type(self, question_type: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–∞ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
        
        Args:
            question_type: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞
        """
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
        question_type = str(question_type).lower().strip()
        
        type_mapping = {
            "recommend": "recommendation",
            "search": "search",
            "find": "search",
            "lookup": "search",
            "compare": "compare", 
            "comparison": "compare",
            "general": "general_question",
            "general_question": "general_question",
            "question": "general_question",
            "step_back": "step_back",
            "back": "step_back",
            "return": "step_back",
            "other": "other",
            "hello": "other",
            "help": "other",
            "thanks": "other",
            "bye": "other"
        }
        
        return type_mapping.get(question_type, question_type)

    def _normalize_json_structure2(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π
        
        Args:
            data: –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –≤—Å–µ–º–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ –ø–æ–ª—è–º–∏
        """
        # –ë–µ—Ä–µ–º –ø—É—Å—Ç–æ–π —à–∞–±–ª–æ–Ω
        normalized = self._get_empty_template()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º question_type –µ—Å–ª–∏ –µ—Å—Ç—å (–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ–≥–æ)
        if "question_type" in data:
            normalized["question_type"] = self._normalize_question_type(data["question_type"])
        
        # –û–±–Ω–æ–≤–ª—è–µ–º filter (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if "filter" in data and isinstance(data["filter"], dict):
            for field in normalized["filter"]:
                if field in data["filter"]:
                    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ç–∏–ø—É
                    if field in ["author", "publisher", "language", "age_restriction", "genre"]:
                        # –≠—Ç–∏ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–∞–º–∏
                        if isinstance(data["filter"][field], list):
                            normalized["filter"][field] = data["filter"][field]
                        elif data["filter"][field]:
                            # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —á–∏—Å–ª–æ, —Å–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫
                            normalized["filter"][field] = [str(data["filter"][field])]
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∫–∞–∫ –µ—Å—Ç—å (–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                        value = data["filter"][field]
                        if value is not None:
                            normalized["filter"][field] = str(value)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º compare (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if "compare" in data and isinstance(data["compare"], dict):
            for field in normalized["compare"]:
                if field in data["compare"]:
                    value = data["compare"][field]
                    if value is not None:
                        normalized["compare"][field] = str(value)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º feedback (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if "feedback" in data and isinstance(data["feedback"], dict):
            for field in ["likes", "dislikes"]:
                if field in data["feedback"]:
                    if isinstance(data["feedback"][field], list):
                        normalized["feedback"][field] = data["feedback"][field]
                    elif data["feedback"][field]:
                        # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–∏–Ω–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Å–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫
                        normalized["feedback"][field] = [str(data["feedback"][field])]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
        if "num_question" in data:
            normalized["num_question"] = str(data["num_question"])
        if "step_back" in data:
            normalized["step_back"] = str(data["step_back"])
        
        return normalized
    
    def _get_empty_template(self) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —à–∞–±–ª–æ–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        
        Returns:
            –ü—É—Å—Ç–æ–π —à–∞–±–ª–æ–Ω JSON
        """
        return {
            "question_type": "",
            "filter": {
                "author": [],
                "publisher": [],
                "year_from": "",
                "year_to": "",
                "language": [],
                "age_restriction": [],
                "genre": [],
                "pages_from": "",
                "pages_to": "",
                "has_illustrations": ""
            },
            "compare": {
                "title1": "",
                "author1": "",
                "title2": "",
                "author2": ""
            },
            "feedback": {
                "likes": [],
                "dislikes": []
            },
            "num_question": "",
            "step_back": ""
        }
    
    def get_status(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º
        """
        return {
            "initialized": self.is_initialized,
            "neural_network_available": self._test_connection(),
            "prompt_loaded": bool(self.system_prompt),
            "prompt_length": len(self.system_prompt) if self.system_prompt else 0
        }


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def main():
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
    neural_parser = NeuralBookParser()
    
    print("=" * 60)
    print("üß† –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ù–ï–ô–†–û–°–ï–¢–ò")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å
    if neural_parser.initialize():
        print("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
        status = neural_parser.get_status()
        print(f"üìä –°—Ç–∞—Ç—É—Å: {status}")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        test_queries = [
            "–ù–∞–π–¥–∏ –∫–Ω–∏–≥–∏ –°—Ç–∏–≤–µ–Ω–∞ –ö–∏–Ω–≥–∞ –≤ –∂–∞–Ω—Ä–µ —É–∂–∞—Å—ã",
            "–ù–∞–π–¥–∏ –∫–Ω–∏–≥–∏ –õ—å–≤–∞ –¢–æ–¥—Å—Ç–æ–≥–æ",
            "–ü–æ—Å–æ–≤–µ—Ç—É–π —á—Ç–æ-—Ç–æ –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ –ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä–∞",
            "–°—Ä–∞–≤–Ω–∏ –í–æ–π–Ω—É –∏ –º–∏—Ä –∏ –ê–Ω–Ω—É –ö–∞—Ä–µ–Ω–∏–Ω—É",
            "–•–æ—á—É –∫–æ—Ä–æ—Ç–∫–∏–µ –∫–Ω–∏–≥–∏"
        ]
        
        for query in test_queries:
            print(f"\nüéØ –ó–∞–ø—Ä–æ—Å: {query}")
            result = neural_parser.parse_query(query)
            print(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç: {json.dumps(result, ensure_ascii=False)}")
            
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å")


if __name__ == "__main__":
    main()

